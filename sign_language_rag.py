#sign_language_rag.py
from sentence_transformers import SentenceTransformer
import numpy as np
import faiss
import openai
from dotenv import load_dotenv
import os

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# Predefined Q&A knowledge base
qa_pairs = []
with open("qa.txt", "r", encoding="utf-8-sig") as f:
    for line in f:
        if "|" in line:
            question, answer = line.strip().split("|", 1)
            question = question.strip().replace('\u200f', '').replace('\ufeff', '')
            answer = answer.strip()
            qa_pairs.append((question, answer))


questions = [q for q, _ in qa_pairs]
answers = [a for _, a in qa_pairs]

# Load multilingual sentence embedding model
model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

# Create FAISS index
q_embeddings = model.encode(questions)
index = faiss.IndexFlatL2(q_embeddings.shape[1])
index.add(np.array(q_embeddings).astype(np.float32))

predefined_questions = {
    'ØªØ­Ù„ÙŠÙ„': "Ù‡Ù„ Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ ØªØ­ØªØ§Ø¬ ØµÙŠØ§Ù…ØŸ",
    'Ø¯ÙˆØ§Ø¡': "Ø£ÙŠÙ† Ø£ØµØ±Ù Ø§Ù„Ø¯ÙˆØ§Ø¡ ÙÙŠ Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ù„Ùƒ Ø³Ù„Ù…Ø§Ù†ØŸ",
    'Ù…ÙˆØ¹Ø¯': "ÙƒÙŠÙ Ø£Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯ ÙÙŠ Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ù„Ùƒ Ø³Ù„Ù…Ø§Ù†ØŸ",
    'Ù†ØªÙŠØ¬Ø©': "Ø£ÙŠÙ† Ø£Ø³ØªÙ„Ù… Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ ÙÙŠ Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ù„Ùƒ Ø³Ù„Ù…Ø§Ù†ØŸ",
    'Ø´ÙƒÙˆÙ‰': "Ø£Ø±ÙŠØ¯ ØªÙ‚Ø¯ÙŠÙ… Ø´ÙƒÙˆÙ‰ ÙÙŠ Ù…Ø³ØªØ´ÙÙ‰ Ø§Ù„Ù…Ù„Ùƒ Ø³Ù„Ù…Ø§Ù†ØŒ ÙƒÙŠÙØŸ",
    'ØµØ±Ù': "Ù‡Ù„ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø¹Ù† Ø§Ù„Ø¯ÙˆØ§Ø¡ØŸ",  # Reuse this for now
    'Ø·ÙˆØ§Ø±Ø¦': "ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ØŒ Ù…Ø§Ø°Ø§ Ø£ÙØ¹Ù„ØŸ",  # Closest match
    'ØµÙŠØ§Ù…': "Ù…ØªÙ‰ Ø£Ø¨Ø¯Ø£ Ø§Ù„ØµÙŠØ§Ù… Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŸ"    # Closest match
}

composite_questions = {
    frozenset(['ØªØ­Ù„ÙŠÙ„', 'ØµÙŠØ§Ù…']): "Ù‡Ù„ ÙƒÙ„ Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ ØªØªØ·Ù„Ø¨ Ø§Ù„ØµÙŠØ§Ù…ØŸ",
    frozenset(['Ù…ÙˆØ¹Ø¯', 'Ù†ØªÙŠØ¬Ø©']): "Ù‡Ù„ Ø£Ø­ØªØ§Ø¬ Ù…ÙˆØ¹Ø¯Ù‹Ø§ Ù„Ø§Ø³ØªÙ„Ø§Ù… Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŸ",
    frozenset(['Ø´ÙƒÙˆÙ‰', 'Ø·ÙˆØ§Ø±Ø¦']): "ÙƒÙŠÙ Ø£Ù‚Ø¯Ù… Ø´ÙƒÙˆÙ‰ Ø¹Ù„Ù‰ Ø®Ø¯Ù…Ø© Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ØŸ",
    frozenset(['Ø¯ÙˆØ§Ø¡', 'ØµØ±Ù']): "Ù‡Ù„ ÙŠÙ…ÙƒÙ† ØµØ±Ù Ø§Ù„Ø¯ÙˆØ§Ø¡ Ù…Ù† ØµÙŠØ¯Ù„ÙŠØ© Ø®Ø§Ø±Ø¬ÙŠØ©ØŸ",
    frozenset(['ØªØ­Ù„ÙŠÙ„', 'Ù†ØªÙŠØ¬Ø©']): "ÙƒÙ… ØªØ³ØªØºØ±Ù‚ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ø§Ù„ÙŠÙ„ØŸ",
    frozenset(['Ù…ÙˆØ¹Ø¯', 'Ø´ÙƒÙˆÙ‰']): "Ù‡Ù„ ÙŠÙ…ÙƒÙ† Ø­Ø¬Ø² Ù…ÙˆØ¹Ø¯ Ù„ØªÙ‚Ø¯ÙŠÙ… Ø´ÙƒÙˆÙ‰ØŸ",
    frozenset(['Ø¯ÙˆØ§Ø¡', 'ØµÙŠØ§Ù…']): "Ù‡Ù„ Ø§Ù„ØµÙŠØ§Ù… ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ ÙØ¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¯ÙˆØ§Ø¡ØŸ",
    frozenset(['Ø·ÙˆØ§Ø±Ø¦', 'ØµØ±Ù']): "Ù‡Ù„ ÙŠÙ…ÙƒÙ† ØµØ±Ù Ø§Ù„Ø¯ÙˆØ§Ø¡ Ù…Ù† Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ØŸ"
}

triple_questions = {
    frozenset(['ØªØ­Ù„ÙŠÙ„', 'ØµÙŠØ§Ù…', 'Ù†ØªÙŠØ¬Ø©']): "Ø¥Ø°Ø§ ØµÙ…Øª Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ØŒ Ù…ØªÙ‰ Ø£Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù†ØªÙŠØ¬Ø©ØŸ",
    frozenset(['Ø´ÙƒÙˆÙ‰', 'Ù…ÙˆØ¹Ø¯', 'Ø·ÙˆØ§Ø±Ø¦']): "ÙƒÙŠÙ Ø£Ù‚Ø¯Ù… Ø´ÙƒÙˆÙ‰ Ø¨Ø¹Ø¯ Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø¯ÙˆÙ† Ù…ÙˆØ¹Ø¯ØŸ",
    frozenset(['ØªØ­Ù„ÙŠÙ„', 'Ù†ØªÙŠØ¬Ø©', 'Ø¯ÙˆØ§Ø¡']): "Ù‡Ù„ Ø£Ø­ØªØ§Ø¬ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„ØµØ±Ù Ø§Ù„Ø¯ÙˆØ§Ø¡ØŸ",
    frozenset(['ØªØ­Ù„ÙŠÙ„', 'Ù…ÙˆØ¹Ø¯', 'Ø·ÙˆØ§Ø±Ø¦']): "Ù‡Ù„ ÙŠÙ…ÙƒÙ† Ø¥Ø¬Ø±Ø§Ø¡ ØªØ­Ù„ÙŠÙ„ ÙÙŠ Ù‚Ø³Ù… Ø§Ù„Ø·ÙˆØ§Ø±Ø¦ Ø¨Ø¯ÙˆÙ† Ù…ÙˆØ¹Ø¯ØŸ",
    frozenset(['Ø¯ÙˆØ§Ø¡', 'Ø´ÙƒÙˆÙ‰', 'ØµØ±Ù']): "Ø¥Ø°Ø§ Ù„Ù… ÙŠÙØµØ±Ù Ù„ÙŠ Ø§Ù„Ø¯ÙˆØ§Ø¡ØŒ ÙƒÙŠÙ Ø£Ù‚Ø¯Ù… Ø´ÙƒÙˆÙ‰ØŸ"
}

# Correct Arabic input using GPT-4o
def correct_text(text):
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Ø£Ù†Øª Ù…ØµØ­Ø­ Ù„ØºÙˆÙŠ Ù…Ø­ØªØ±Ù. ØµØ­Ø­ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù†Ø­ÙˆÙŠØ§Ù‹ ÙˆØ¥Ù…Ù„Ø§Ø¦ÙŠØ§Ù‹ ÙÙ‚Ø· Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ù…Ø¹Ù†Ø§Ù‡Ø§."},
            {"role": "user", "content": text}
        ],
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()

# Generate final answer using retrieved context
def generate_answer(question, context):
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµØ­ÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰. Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„. Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø¹Ù„Ø§Ù‚Ø© ÙˆØ§Ø¶Ø­Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙˆØ§Ù„Ø³Ø¤Ø§Ù„ØŒ Ø£Ø¬Ø¨ Ø¨Ù€: Ù„Ø§ Ø£Ø¹Ù„Ù…. Ù„Ø§ ØªØ®ØªØ±Ø¹ Ø¥Ø¬Ø§Ø¨Ø© Ø£Ø¨Ø¯Ø§Ù‹."},
            {"role": "user", "content": f"Ø§Ù„Ø³Ø¤Ø§Ù„: {question}\nØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø©: {context}"}
        ],
        temperature=0.3,
    )
    return response.choices[0].message.content.strip()

# Reformulate input into a clear question (if needed)
def reformulate_to_question(sentence):
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙÙŠ Ù…Ø³ØªØ´ÙÙ‰. ÙˆØ¸ÙŠÙØªÙƒ Ù‡ÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¬Ù…Ù„ Ø¥Ù„Ù‰ Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ø¶Ø­Ø© ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØªØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰ Ø£Ùˆ Ø§Ù„Ø¹Ù„Ø§Ø¬ Ø£Ùˆ Ø§Ù„Ù…Ø±ÙŠØ¶. Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø§Ù„Ø¬Ù…Ù„Ø© Ù…Ø±ØªØ¨Ø·Ø©ØŒ Ø£Ø¬Ø¨ ÙÙ‚Ø· Ø¨ÙƒÙ„Ù…Ø©: ØºÙŠØ± Ù…ØªØ¹Ù„Ù‚ Ø¨Ø§Ù„Ù…Ø³ØªØ´ÙÙ‰."},
            {"role": "user", "content": sentence}
        ],
        temperature=0.2,
    )
    return response.choices[0].message.content.strip()

# Detected words from YOLO mapped to Arabic
translation_dict = {
    'analysis': 'ØªØ­Ù„ÙŠÙ„',
    'appointment': 'Ù…ÙˆØ¹Ø¯',
    'complaint': 'Ø´ÙƒÙˆÙ‰',
    'dispensing': 'ØµØ±Ù',
    'emergency': 'Ø·ÙˆØ§Ø±Ø¦',
    'fasting': 'ØµÙŠØ§Ù…',
    'medicine': 'Ø¯ÙˆØ§Ø¡',
    'result': 'Ù†ØªÙŠØ¬Ø©'
}

# ğŸ”‘ MAIN callable function for your Flask app
def get_llm_answer(detected_word_en, sentence_words_arabic, threshold=10.0):
    detected_word_ar = translation_dict.get(detected_word_en.lower(), "")
    if not detected_word_ar and sentence_words_arabic:
        detected_word_ar = sentence_words_arabic[-1]

    detected_word_ar = detected_word_ar.strip()

    question = None
    unique_words = set(sentence_words_arabic)

    for combo, q in triple_questions.items():
        if combo.issubset(unique_words):
            question = q
            break

    if not question:
        for combo, q in composite_questions.items():
            if combo.issubset(unique_words):
                question = q
                break

    if not question:
        question = predefined_questions.get(detected_word_ar)

    if not question:
        for word in reversed(sentence_words_arabic):
            if word in predefined_questions:
                question = predefined_questions[word]
                break

    if not question:
        return "Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù‡Ø°Ù‡ Ø§Ù„ÙƒÙ„Ù…Ø©."

    print("â“ Predefined question:", question)

    input_embedding = model.encode([question])
    D, I = index.search(np.array(input_embedding).astype(np.float32), k=1)
    distance = D[0][0]
    print("ğŸ“ Similarity Distance:", distance)

    if distance > threshold:
        print("âŒ No relevant match found.")
        return "Ø¹Ø°Ø±Ù‹Ø§ØŒ Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ø¹Ù† Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±."

    top_question = questions[I[0][0]]
    context = answers[I[0][0]]
    print("ğŸ” Top matched question:", top_question)
    print("ğŸ“š Retrieved answer:", context)

    response = generate_answer(question, context)
    print("ğŸ§  Final GPT Answer:", response)

    return {
        "question": question,
        "answer": response
    }
