# Mu'een (Ù…ÙØ¹ÙŠÙ†) - Sign Language Hospital Assistant

An intelligent web application designed to assist deaf and mute patients in hospital settings by recognizing Arabic sign language and providing real-time answers to their queries.

## ğŸ¯ Project Overview

**Mu'een** is a specialized system developed for hospital reception areas that bridges the communication gap between deaf/mute patients and healthcare staff. The system uses computer vision to detect sign language gestures and provides intelligent responses through a RAG (Retrieval-Augmented Generation) system powered by OpenAI's GPT-4.

### Key Features

- **Real-time Sign Language Detection**: Uses YOLOv11 model trained on custom dataset
- **Arabic Language Support**: Full Arabic interface and responses
- **Intelligent Question-Answer System**: RAG-based system for accurate responses
- **Web-Based Interface**: Easy-to-use browser interface
- **Live Camera Feed**: Real-time video processing and detection

## ğŸ¥ Target Use Case

Specifically designed for **King Salman Hospital** reception area to help deaf and mute patients with:
- Booking appointments
- Getting lab results
- Finding pharmacy locations
- Emergency procedures

## ğŸ—‚ï¸ Project Structure

```
mu'een/
â”œâ”€â”€ app.py                          # Main Flask application
â”œâ”€â”€ sign_language_rag.py           # RAG system and LLM integration
â”œâ”€â”€ SignLanguage_YOLO11_Final.ipynb # Model training notebook
â”œâ”€â”€ qa.txt                         # Knowledge base Q&A pairs
â”œâ”€â”€ data.yaml                      # Dataset configuration
â”œâ”€â”€ run_YOLO_cam.py               # Standalone camera testing
â”œâ”€â”€ resize.py                     # Image preprocessing utility
â”œâ”€â”€ creating_images.py            # Dataset creation tool
â”œâ”€â”€ change_image_names.py         # Dataset organization utility
â”œâ”€â”€ yolov11_run/weights/best.pt   # Trained YOLO model weights
â””â”€â”€ templates/
    â””â”€â”€ index.html                # Web interface
```

## ğŸ› ï¸ Installation & Setup

### Prerequisites

- Python 3.8 or higher
- Webcam/Camera device
- OpenAI API key
- Git


### Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 2: Environment Setup

Create a `.env` file in the root directory:

```env
OPENAI_API_KEY=your_openai_api_key_here
```

### Step 3: Download Model Weights

Ensure the trained YOLO model is placed at:
```
yolov11_run/weights/best.pt
```

## ğŸš€ Running the Application

### Start the Web Application

```bash
python app.py
```

The application will be available at: `http://localhost:5000`


## ğŸ“Š Supported Sign Language Words

The system currently recognizes 8 medical-related sign language gestures:

| **English** | **Arabic** | **Context** |
|-------------|------------|-------------|
| Analysis    | ØªØ­Ù„ÙŠÙ„      | Lab tests |
| Appointment | Ù…ÙˆØ¹Ø¯       | Booking appointments |
| Complaint   | Ø´ÙƒÙˆÙ‰       | Filing complaints |
| Dispensing  | ØµØ±Ù        | Pharmacy services |
| Emergency   | Ø·ÙˆØ§Ø±Ø¦      | Emergency situations |
| Fasting     | ØµÙŠØ§Ù…       | Pre-test fasting |
| Medicine    | Ø¯ÙˆØ§Ø¡       | Medication queries |
| Result      | Ù†ØªÙŠØ¬Ø©      | Test results |

## ğŸ§  How It Works

1. **Sign Detection**: Camera captures real-time video feed
2. **YOLO Processing**: Custom YOLOv11 model detects sign language gestures
3. **Translation**: English predictions are translated to Arabic
4. **Sentence Building**: Multiple signs are combined into meaningful sentences
5. **RAG System**: Sentence is processed through retrieval system to find relevant information
6. **LLM Response**: OpenAI GPT-4 generates contextual Arabic responses
7. **Display**: Results are shown in real-time web interface

## ğŸ”§ Technical Architecture

### Core Components

- **Flask Web Server**: Handles HTTP requests and serves the web interface
- **YOLOv11 Model**: Custom-trained computer vision model for sign detection
- **FAISS Vector Database**: Efficient similarity search for question matching
- **OpenAI GPT-4**: Natural language generation for responses
- **Sentence Transformers**: Multilingual embeddings for semantic search


## ğŸ¯ Custom Dataset

The sign language dataset was **self-created** specifically for this project:
- **8 medical sign language gestures**
- **Custom annotations** for hospital context
- **YOLOv11 format** for object detection
- **Arabic medical terminology** focus


## ğŸ“‹ Requirements

```
flask
ultralytics
opencv-python
sentence-transformers
faiss-cpu
openai
python-dotenv
numpy
torch
torchvision
```


## ğŸ‘¥ Team members

This project was developed by a team of five students:

Shaden Alturki

Abdullah Aljubran

Jana Almalki

Shahad Albalawi

Raghad Alqahtani



**Mu'een (Ù…ÙØ¹ÙŠÙ†)** - Making healthcare accessible for everyone through technology.
